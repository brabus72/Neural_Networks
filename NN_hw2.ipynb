{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание №1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Попробуйте обучить нейронную сеть на Keras с другими параметрами. \n",
    "        Опишите в комментарии к уроку - какой результата вы добились от нейросети? Что помогло вам улучшить ее точность?</li>\n",
    "    <li>Поработайте с документацией Keras.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0572 - accuracy: 0.9802\n",
      "Epoch 2/60\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0271 - accuracy: 0.9909\n",
      "Epoch 3/60\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0204 - accuracy: 0.9931\n",
      "Epoch 4/60\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0169 - accuracy: 0.9943\n",
      "Epoch 5/60\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0141 - accuracy: 0.9952\n",
      "Epoch 6/60\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0125 - accuracy: 0.9957\n",
      "Epoch 7/60\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0114 - accuracy: 0.9960\n",
      "Epoch 8/60\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0093 - accuracy: 0.9968\n",
      "Epoch 9/60\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0091 - accuracy: 0.9967\n",
      "Epoch 10/60\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0078 - accuracy: 0.9973\n",
      "Epoch 11/60\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0070 - accuracy: 0.9976\n",
      "Epoch 12/60\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0070 - accuracy: 0.9976\n",
      "Epoch 13/60\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0065 - accuracy: 0.9977\n",
      "Epoch 14/60\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0054 - accuracy: 0.9981\n",
      "Epoch 15/60\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0049 - accuracy: 0.9983\n",
      "Epoch 16/60\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0049 - accuracy: 0.9982\n",
      "Epoch 17/60\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 18/60\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0042 - accuracy: 0.9985\n",
      "Epoch 19/60\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0045 - accuracy: 0.9984\n",
      "Epoch 20/60\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 21/60\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 22/60\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 23/60\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 24/60\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 25/60\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0034 - accuracy: 0.9988\n",
      "Epoch 26/60\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 27/60\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 28/60\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 29/60\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 30/60\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 31/60\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0028 - accuracy: 0.9990\n",
      "Epoch 32/60\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 33/60\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0034 - accuracy: 0.9988\n",
      "Epoch 34/60\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 35/60\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 36/60\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 37/60\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 38/60\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch 39/60\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 40/60\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 41/60\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 42/60\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 43/60\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 44/60\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 45/60\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 46/60\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 47/60\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0019 - accuracy: 0.99940s - loss: 0.0017 - accuracy:  - ETA: 0s - loss: 0.0017 - accura - ETA: 0s - loss: 0.0017 - accuracy: 0.99 - ETA: 0s - loss: 0.0018 - accu\n",
      "Epoch 48/60\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 49/60\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 50/60\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 51/60\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 52/60\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 53/60\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 54/60\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 55/60\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 56/60\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 57/60\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 58/60\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 59/60\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 60/60\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0022 - accuracy: 0.9993\n",
      "10000/10000 [==============================] - 1s 105us/step\n",
      "[7 2 1 0 4]\n",
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "# The full neural network code!\n",
    "###############################\n",
    "import numpy as np\n",
    "import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "\n",
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "# Flatten the images.\n",
    "train_images = train_images.reshape((-1, 784))\n",
    "test_images = test_images.reshape((-1, 784))\n",
    "\n",
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(128, activation='relu', input_shape=(784,)),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='binary_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=60,\n",
    "  batch_size=96,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  test_images,\n",
    "  to_categorical(test_labels)\n",
    ")\n",
    "\n",
    "# Save the model to disk.\n",
    "model.save_weights('model.h5')\n",
    "\n",
    "# Load the model from disk later using:\n",
    "# model.load_weights('model.h5')\n",
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(test_images[:5])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(test_labels[:5]) # [7, 2, 1, 0, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "В первую очередь, сделаем самые очевидные изменения в настройках нейронной сети - это изменение количества эпох обучения и размер батчей (epochs=60, batch_size=96). После ряда эксперементов мы получили следующий результат:\n",
    "\n",
    "Epoch 60/60\n",
    "\n",
    "60000/60000 [==============================] - 3s 48us/step - loss: 0.0088 - accuracy: 0.9969\n",
    "\n",
    "10000/10000 [==============================] - 1s 52us/step\n",
    "\n",
    "[7 2 1 0 4]\n",
    "[7 2 1 0 4]\n",
    "\n",
    "\n",
    "Теперь попробуем подобрать loss функцию (при loss=binary_crossentropy) и после ряда экспериментов получили следующий результат:\n",
    "\n",
    "Epoch 56/60\n",
    "\n",
    "60000/60000 [==============================] - 5s 80us/step - loss: 0.0012 - accuracy: 0.9996\n",
    "\n",
    "Epoch 60/60\n",
    "\n",
    "60000/60000 [==============================] - 5s 80us/step - loss: 0.0021 - accuracy: 0.9993\n",
    "\n",
    "10000/10000 [==============================] - 1s 67us/step\n",
    "\n",
    "[7 2 1 0 4]\n",
    "[7 2 1 0 4]\n",
    "\n",
    "\n",
    "Увеличение количества нейронов входного и скрытого слоёв (до 128 и 256) позволило резко увеличить accuracy за гораздо меньшее количество эпох, сделать изменение значений loss от эпохи к эпохе более стабильной и получить следующие результаты:\n",
    "\n",
    "\n",
    "Epoch 60/60\n",
    "\n",
    "60000/60000 [==============================] - 9s 144us/step - loss: 0.0013 - accuracy: 0.9996\n",
    "\n",
    "10000/10000 [==============================] - 1s 102us/step\n",
    "\n",
    "[7 2 1 0 4]\n",
    "[7 2 1 0 4]\n",
    "\n",
    "\n",
    "Epoch 200/200\n",
    "\n",
    "60000/60000 [==============================] - 10s 162us/step - loss: 8.7497e-04 - accuracy: 0.9998\n",
    "\n",
    "10000/10000 [==============================] - 2s 154us/step\n",
    "\n",
    "[7 2 1 0 4]\n",
    "[7 2 1 0 4]\n",
    "\n",
    "Итак, можно отметить следующее:\n",
    "\n",
    "   - большое влияние на accuracy и результативность обучения в целом, имеет количество нейронов в слоях (128 и 256);\n",
    "   - размер батча имеет влияние на скорость обучения 1 эпохи;\n",
    "   - изменение loss на 'binary_crossentropy' позволило улучшить результат accuracy.\n",
    "\n",
    "\n",
    "\n",
    "2.\n",
    "\n",
    "Интересной мне показалась возможность создания своей loss, например:\n",
    "\n",
    "\n",
    "    def my_loss_fn(y_true, y_pred):\n",
    "    \n",
    "        squared_difference = tf.square(y_true - y_pred)\n",
    "    \n",
    "        return tf.reduce_mean(squared_difference, axis=-1)  # Note the `axis=-1`\n",
    "\n",
    "    model.compile(optimizer='adam', loss=my_loss_fn)\n",
    "\n",
    "\n",
    "И в целом, изучение-просмотр документации по Keras оставило впечатление, что то что мы сейчас делаем cможет и обезьяна, а осмысленное понимание построения графа нейронной сети в лучшем случае придёт не скоро."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
